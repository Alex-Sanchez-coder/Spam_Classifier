{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classifier\n",
    "\n",
    "## Getting Started\n",
    "Spam refers to unwanted email, often in the form of advertisements. In the literature, an email that is **not** spam is called *ham*. Most email providers offer automatic spam filtering, where spam emails will be moved to a separate inbox based on their contents. Of course this requires being able to scan an email and determine whether it is spam or ham, a classification problem. \n",
    "\n",
    "### Choice of Algorithm\n",
    "This notebook presents the Naive-Bayes approach, however a 2nd method was implemented  (a Neural Network), which is in .py file and all weights are in csvs, however it should be noted other algorithms can be implemented such as:k-nearest neighbour algorithm, but this may be less accurate. Logistic regression is another option.\n",
    "\n",
    "## Training Data\n",
    "The training data is described below and has 1000 rows. There is also a 500 row set of test data. These are functionally identical to the training data, they are just in a separate csv file to encourage you to split out your training and test data. You should consider how to best make use of all available data without overfitting, and to help produce an unbiased estimate for your classifier's accuracy.\n",
    "\n",
    "The cell below loads the training data into a variable called `training_spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(training_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 1000 rows and 55 columns. Each row corresponds to one email message. The first column is the _response_ variable and describes whether a message is spam `1` or ham `0`. The remaining 54 columns are _features_ that you will use to build a classifier. These features correspond to 54 different keywords (such as \"money\", \"free\", and \"receive\") and special characters (such as \":\", \"!\", and \"$\"). A feature has the value `1` if the keyword appears in the message and `0` otherwise.\n",
    "\n",
    "As mentioned there is also a 500 row set of *test data*. It contains the same 55 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam testing data set: (500, 55)\n",
      "[[1 0 0 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "print(testing_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "Naive-Bayes approach implementation\n",
    "\n",
    "### Submission Requirements\n",
    "The code uses a variable with the name `classifier`. This object have a method called `predict` which takes input data and returns class predictions. The input will be a single $n \\times 54$ numpy array, and the classifier is going to return a numpy array of length $n$ with classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class SpamClassifier:\n",
    "    \n",
    "#   \n",
    "    def __init__(self, data = None):\n",
    "  \n",
    "        if data is not None:\n",
    "            self.data = data\n",
    "            \n",
    "            self.data_outputs = self.data[:, 0]  # 1 = spam, 0 = ham\n",
    "            self.data_inputs = self.data[:, 1:]  # All 54 features values over 1000 samples for training mode\n",
    "            self.n_samples, self.n_features = self.data_inputs.shape  # Number of samples (1000), Number of features (54)\n",
    "            \n",
    "            self.total_spam = np.count_nonzero(self.data_outputs) # Counting Spam\n",
    "            self.total_ham = self.n_samples - self.total_spam # Counting Ham\n",
    "            \n",
    "        \n",
    "    def estimate_log_class_priors(self):\n",
    "    \n",
    "        ## Probabilities\n",
    "        prob_spam = self.total_spam / self.n_samples\n",
    "        prob_ham = self.total_ham / self.n_samples\n",
    "        probs = np.array([prob_ham, prob_spam], dtype=float)\n",
    "\n",
    "        ## Logarithm\n",
    "        log_class_priors = np.log10(probs)\n",
    "\n",
    "        return log_class_priors\n",
    "        \n",
    "#\n",
    "    def values_ones_spam_ham(self, binary_number):\n",
    "        \n",
    "        #Binary number could be either 1 or 0\n",
    "        \n",
    "        spam_ham_data_ones_zeros = copy.deepcopy(self.data_inputs) # Copy data to be deleted\n",
    "        ones_zeros_index_array = [] # This list contains all indices that has 0s (ham) or 1s (spam) in input label\n",
    "        values_ones_spam_ham = np.array([]) # This array saves the frequency that a \"1\" or \"0\" is registered based on filtered data\n",
    "\n",
    "        for ones_zeros in range(self.n_samples):\n",
    "            if self.data_outputs[ones_zeros] == binary_number: \n",
    "                ones_zeros_index_array.append(ones_zeros) # Saving indices for hams or spams\n",
    "\n",
    "        spam_ham_data_ones_zeros = np.delete(spam_ham_data_ones_zeros, tuple(ones_zeros_index_array), axis = 0) # Creating data according to input label\n",
    "\n",
    "        for column in range(self.n_features):\n",
    "            ones_spam_ham = np.count_nonzero(spam_ham_data_ones_zeros[:,column]) #Counting 1s (keywords) in spam_ham_data_ones_zeros matrix\n",
    "            values_ones_spam_ham = np.append(values_ones_spam_ham, ones_spam_ham) #Adding values in an array\n",
    "            \n",
    "        return values_ones_spam_ham\n",
    "    \n",
    "#    \n",
    "    def estimate_log_class_conditional_likelihoods(self, alpha=1):\n",
    "\n",
    "        ## Probabilities\n",
    "        \n",
    "        values_ones_spam = self.values_ones_spam_ham(0) # To delete 0s\n",
    "        values_ones_ham = self.values_ones_spam_ham(1) # To delete 1s\n",
    "            \n",
    "        ## Calculating probabilities per feature\n",
    "        prob_ones_spam = np.zeros([1, self.n_features]) #array to save probabilities\n",
    "        prob_ones_ham = np.zeros([1, self.n_features]) #array to save probabilities\n",
    "\n",
    "        for i in range(self.n_features):\n",
    "\n",
    "            # Cardinality must be 2 in all data_inputs´columns as result of is a binary conditional\n",
    "            features_values = np.unique(self.data_inputs[:,i]) # Calculating unique values per column in data inputs\n",
    "            cardinality = len(features_values) # Getting cardinality per calumn\n",
    "\n",
    "            #Implementing probabilities by using laplace method\n",
    "            prob_ones_spam[0, i] = (values_ones_spam[i] + alpha)/(self.total_spam + (cardinality * alpha))\n",
    "            prob_ones_ham[0, i] = (values_ones_ham[i] + alpha)/(self.total_ham + (cardinality * alpha))\n",
    "\n",
    "        conditional_likelihoods = copy.deepcopy(prob_ones_ham)\n",
    "        conditional_likelihoods = np.append(conditional_likelihoods, prob_ones_spam, axis = 0)\n",
    "        conditional_likelihoods = np.log10(conditional_likelihoods)\n",
    "\n",
    "        return conditional_likelihoods\n",
    "    \n",
    "#\n",
    "    def train(self):\n",
    "        \n",
    "        log_class_priors = self.estimate_log_class_priors()\n",
    "        \n",
    "        log_class_conditional_likelihoods = self.estimate_log_class_conditional_likelihoods()\n",
    "        \n",
    "        np.savetxt('log_class_priors.csv', log_class_priors, delimiter=\",\")\n",
    "        np.savetxt('log_class_conditional_likelihoods.csv', log_class_conditional_likelihoods, delimiter=\",\")\n",
    "\n",
    "#    \n",
    "    def predict(self, test_data):\n",
    "        \n",
    "        # Open probabilities from latest training \n",
    "        log_class_priors = np.loadtxt(open(\"log_class_priors.csv\"), delimiter=\",\")\n",
    "        log_class_conditional_likelihoods = np.loadtxt(open(\"log_class_conditional_likelihoods.csv\"), delimiter=\",\")\n",
    "        \n",
    "        n_test_samples, n_test_features = test_data.shape # Number of samples (n), Number of features (54)\n",
    "        \n",
    "        class_predictions = np.array([])\n",
    "\n",
    "        for samples in range(n_test_samples):\n",
    "\n",
    "            ham = log_class_priors[0] + (test_data[samples] @ log_class_conditional_likelihoods[0])\n",
    "            spam = log_class_priors[1] + (test_data[samples] @ log_class_conditional_likelihoods[1])\n",
    "\n",
    "            if ham > spam:\n",
    "                class_predictions_values = 0\n",
    "            else:\n",
    "                class_predictions_values = 1\n",
    "\n",
    "            class_predictions = np.append(class_predictions, class_predictions_values)\n",
    "\n",
    "        return class_predictions\n",
    "    \n",
    "### Function ###\n",
    "def create_classifier(data):\n",
    "    classifier = SpamClassifier(training_spam_data) # Initializing the Class\n",
    "    classifier.train() # Training\n",
    "    return classifier\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Importing Training data from /data/...\n",
    "    training_spam_data = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\")\n",
    "    classifier = create_classifier(training_spam_data)\n",
    "    \n",
    "    # Insert new data\n",
    "    #predictions = classifier.predict(test_data)\n",
    "    \n",
    "    # Comments\n",
    "    # Adding the Neural Network file inside the folder and the link for the video is also here:\n",
    "    # https://video-uk.engagelms.com/share/aecytBqLyKvppF1Ah6mXUuXXtSaLEA123qsXBgPp8J7Rykss3Rochwrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Details\n",
    "The classifier will be tested against some hidden data from the same source as the original. The accuracy (percentage of classifications correct) will be calculated, then benchmarked against common methods.\n",
    "\n",
    "#### Test Cell\n",
    "The following code will run the classifier against the provided test data. To enable it, set the constant `SKIP_TESTS` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_TESTS = True\n",
    "\n",
    "if not SKIP_TESTS:\n",
    "    testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "    test_data = testing_spam[:, 1:]\n",
    "    test_labels = testing_spam[:, 0]\n",
    "\n",
    "    predictions = classifier.predict(test_data)\n",
    "    accuracy = np.count_nonzero(predictions == test_labels)/test_labels.shape[0]\n",
    "    print(f\"Accuracy on test data is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59d6bceb43ad854b001cc67cf0fc07f9",
     "grade": false,
     "grade_id": "cell-ce83a675162843d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Make sure you follow the instructions on the assignment page to submit your video.\n",
      "Failing to include this could result in an overall grade of zero for both parts.\n",
      "\n",
      "All checks passed. When you are ready to submit, upload the notebook and readme file to the\n",
      "assignment page, without changing any filenames.\n",
      "\n",
      "If you need to submit multiple files, you can archive them in a .zip file. (No other format.)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "fail = False;\n",
    "\n",
    "if not SKIP_TESTS:\n",
    "    fail = True;\n",
    "    print(\"You must set the SKIP_TESTS constant to True in the cell above.\")\n",
    "    \n",
    "p3 = pathlib.Path('./spamclassifier.ipynb')\n",
    "if not p3.is_file():\n",
    "    fail = True\n",
    "    print(\"This notebook file must be named spamclassifier.ipynb\")\n",
    "    \n",
    "if \"create_classifier\" not in dir():\n",
    "    fail = True;\n",
    "    print(\"You must include a function called create_classifier.\")\n",
    "\n",
    "if \"my_accuracy_estimate\" not in dir():\n",
    "    fail = True;\n",
    "    print(\"You must include a function called my_accuracy_estimate.\")\n",
    "else:\n",
    "    if my_accuracy_estimate() == 0.5:\n",
    "        print(\"Warning:\")\n",
    "        print(\"You do not seem to have provided an accuracy estimate, it is set to 0.5.\")\n",
    "        print(\"This is the actually the worst possible accuracy – if your classifier\")\n",
    "        print(\"got 0.1 then it could invert its results to get 0.9!\")\n",
    "    \n",
    "print(\"INFO: Make sure you follow the instructions on the assignment page to submit your video.\")\n",
    "print(\"Failing to include this could result in an overall grade of zero for both parts.\")\n",
    "print()\n",
    "\n",
    "if fail:\n",
    "    sys.stderr.write(\"Your submission is not ready! Please read and follow the instructions above.\")\n",
    "else:\n",
    "    print(\"All checks passed. When you are ready to submit, upload the notebook and readme file to the\")\n",
    "    print(\"assignment page, without changing any filenames.\")\n",
    "    print()\n",
    "    print(\"If you need to submit multiple files, you can archive them in a .zip file. (No other format.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "badbc892f539e03ad0acdb369f7e0993",
     "grade": true,
     "grade_id": "cell-b64bc40ab6485b50",
     "locked": true,
     "points": 100,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell. Please do not modify or delete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
